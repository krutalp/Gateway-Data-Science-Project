{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "data_dir = os.path.join(\"./\", \"breast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "modules=list(resnet18.children())[:-1]\n",
    "resnet18=nn.Sequential(*modules)\n",
    "for p in resnet18.parameters():\n",
    "    p.requires_grad = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract features from dataset including all resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1         2         3         4         5         6         7     \\\n",
      "0    0.531274  0.594747  0.590899  0.722041  0.465432  0.322455  0.520599   \n",
      "1    0.139732  0.348665  0.318642  0.289941  0.255532  0.188617  0.339818   \n",
      "2    0.337814  0.550642  0.594561  0.482355  0.506674  0.407469  0.211697   \n",
      "3    1.492059  1.213679  1.026551  1.200261  1.401562  1.081025  1.293290   \n",
      "4    0.270016  0.288044  0.612079  0.660533  0.628363  0.218116  0.069697   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "508  0.105080  0.219287  0.172791  0.211580  0.149814  0.238355  0.406067   \n",
      "509  1.018662  1.056771  0.957266  1.212001  1.137472  1.204388  0.621209   \n",
      "510  0.318730  0.158945  0.156660  0.212991  0.118137  0.092524  0.370001   \n",
      "511  0.126240  0.048812  0.265091  0.366576  0.206605  0.364724  0.293995   \n",
      "512  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         8         9         10    ...      3739      3740      3741  \\\n",
      "0    0.513436  0.689455  0.709559  ...  1.867392  2.094951  1.562501   \n",
      "1    0.282234  0.145335  0.375806  ...  0.114428  0.309604  0.139374   \n",
      "2    0.134016  0.460912  0.582106  ...  1.073094  1.123510  1.416093   \n",
      "3    1.626229  1.611910  1.625107  ...  1.426222  1.541353  2.047864   \n",
      "4    0.142370  0.204159  0.793633  ...  0.119417  0.266798  0.353356   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "508  0.390755  0.174785  0.075354  ...  0.145907  0.240250  0.181667   \n",
      "509  1.389215  0.992055  1.072873  ...  1.574341  1.623722  1.972367   \n",
      "510  0.386550  0.146325  0.054660  ...  0.455894  0.598580  0.340262   \n",
      "511  0.437457  0.309837  0.185114  ...  0.105052  0.159993  0.031121   \n",
      "512  0.000000  0.000000  0.000000  ...  1.000000  1.000000  1.000000   \n",
      "\n",
      "         3742      3743      3744      3745      3746      3747      3748  \n",
      "0    2.731224  2.420168  2.319472  1.467218  1.678670  1.123754  1.333200  \n",
      "1    0.101642  0.183994  0.204981  0.105868  0.509212  0.097942  0.285788  \n",
      "2    1.625812  1.030377  0.807981  1.341565  0.664007  1.279427  0.849752  \n",
      "3    1.984226  1.006549  1.018086  1.311624  0.937914  1.861820  0.976252  \n",
      "4    0.274618  0.320843  0.227027  0.144096  0.360435  0.304560  0.350521  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "508  0.311163  0.113164  0.043497  0.165219  0.249359  0.465376  0.215181  \n",
      "509  2.430358  1.368123  1.384982  1.422703  1.886793  1.519427  1.423076  \n",
      "510  0.563239  0.614330  0.510219  0.401049  0.546771  1.029743  0.869732  \n",
      "511  0.030509  0.099951  0.177597  0.056729  0.164157  0.054945  0.150832  \n",
      "512  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
      "\n",
      "[513 rows x 3748 columns]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "image_features = np.zeros((513, 1))\n",
    "\n",
    "resnet18.eval()\n",
    " \n",
    "with torch.no_grad():\n",
    "    for data in dataloader: \n",
    "        image, label = data\n",
    "        encoding = resnet18(image) \n",
    "\n",
    "        encoding_np = encoding.numpy()\n",
    "        label = label.numpy()\n",
    "\n",
    "        encoding_np = encoding_np.reshape(1, 512)\n",
    "        encoding_np = np.append(encoding_np, label)\n",
    "        encoding_np = encoding_np.reshape(513, 1)\n",
    "\n",
    "        image_features = np.append(image_features, encoding_np, axis=1)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# drop first row of zeros\n",
    "image_features_df = pd.DataFrame(image_features)\n",
    "image_features_df = image_features_df.iloc[:, 1:]\n",
    "print(image_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_df.to_csv('features_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3748,)\n",
      "(3748, 513)\n"
     ]
    }
   ],
   "source": [
    "image_features_df_T = image_features_df.T\n",
    "image_features_df_T = pd.DataFrame(image_features_df_T)\n",
    "labels = image_features_df_T.iloc[:, 512]\n",
    "print(labels.shape)\n",
    "print(image_features_df_T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_x = image_features_df_T.iloc[:, :512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the model is:  0.9057777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set_x, labels, stratify = labels, test_size=0.3)\n",
    "\n",
    "model_all = LogisticRegressionCV(max_iter = 5000)\n",
    "model_all.fit(X_train, y_train)\n",
    "s = model_all.score(X_test, y_test)\n",
    "print(\"The score of the model is: \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.208780</td>\n",
       "      <td>0.152388</td>\n",
       "      <td>1.255196</td>\n",
       "      <td>0.453387</td>\n",
       "      <td>0.204274</td>\n",
       "      <td>0.396641</td>\n",
       "      <td>0.662290</td>\n",
       "      <td>2.381847</td>\n",
       "      <td>0.763311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031166</td>\n",
       "      <td>0.476478</td>\n",
       "      <td>1.420786</td>\n",
       "      <td>0.130925</td>\n",
       "      <td>0.158760</td>\n",
       "      <td>0.308012</td>\n",
       "      <td>1.168912</td>\n",
       "      <td>0.035456</td>\n",
       "      <td>0.235910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431392</td>\n",
       "      <td>0.269095</td>\n",
       "      <td>0.121084</td>\n",
       "      <td>1.369295</td>\n",
       "      <td>0.165390</td>\n",
       "      <td>0.200180</td>\n",
       "      <td>0.755715</td>\n",
       "      <td>1.141574</td>\n",
       "      <td>2.679910</td>\n",
       "      <td>0.191846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.298568</td>\n",
       "      <td>1.560464</td>\n",
       "      <td>0.437376</td>\n",
       "      <td>0.089650</td>\n",
       "      <td>0.352928</td>\n",
       "      <td>1.118457</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.135839</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.189157</td>\n",
       "      <td>0.248151</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>1.353558</td>\n",
       "      <td>0.167985</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>0.603197</td>\n",
       "      <td>0.640468</td>\n",
       "      <td>1.740507</td>\n",
       "      <td>0.496436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028693</td>\n",
       "      <td>0.393584</td>\n",
       "      <td>2.182479</td>\n",
       "      <td>0.250761</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>0.213455</td>\n",
       "      <td>0.870525</td>\n",
       "      <td>0.115242</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181322</td>\n",
       "      <td>0.431159</td>\n",
       "      <td>0.183613</td>\n",
       "      <td>1.435808</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.258571</td>\n",
       "      <td>0.376346</td>\n",
       "      <td>1.099299</td>\n",
       "      <td>1.455429</td>\n",
       "      <td>0.377059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>0.269249</td>\n",
       "      <td>1.557632</td>\n",
       "      <td>0.267773</td>\n",
       "      <td>0.207152</td>\n",
       "      <td>0.158261</td>\n",
       "      <td>1.115834</td>\n",
       "      <td>0.108024</td>\n",
       "      <td>0.225783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.557896</td>\n",
       "      <td>0.148965</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>1.440755</td>\n",
       "      <td>0.265388</td>\n",
       "      <td>0.100576</td>\n",
       "      <td>0.482407</td>\n",
       "      <td>1.267099</td>\n",
       "      <td>3.177758</td>\n",
       "      <td>0.391448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.503995</td>\n",
       "      <td>1.973315</td>\n",
       "      <td>0.350742</td>\n",
       "      <td>0.277134</td>\n",
       "      <td>0.234877</td>\n",
       "      <td>1.566571</td>\n",
       "      <td>0.074112</td>\n",
       "      <td>0.155174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0.409747</td>\n",
       "      <td>0.057417</td>\n",
       "      <td>0.243835</td>\n",
       "      <td>1.170132</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>0.518152</td>\n",
       "      <td>1.096409</td>\n",
       "      <td>0.612581</td>\n",
       "      <td>2.396959</td>\n",
       "      <td>0.879318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>0.868811</td>\n",
       "      <td>1.065686</td>\n",
       "      <td>0.072270</td>\n",
       "      <td>0.250466</td>\n",
       "      <td>0.306638</td>\n",
       "      <td>0.781481</td>\n",
       "      <td>0.102368</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>0.487585</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.133818</td>\n",
       "      <td>0.907975</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>0.533047</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>0.767510</td>\n",
       "      <td>1.636675</td>\n",
       "      <td>0.891331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>0.961497</td>\n",
       "      <td>1.074510</td>\n",
       "      <td>0.163653</td>\n",
       "      <td>0.259980</td>\n",
       "      <td>0.249659</td>\n",
       "      <td>0.396892</td>\n",
       "      <td>0.080202</td>\n",
       "      <td>0.217580</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>0.432066</td>\n",
       "      <td>0.216163</td>\n",
       "      <td>0.218408</td>\n",
       "      <td>1.073746</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.340214</td>\n",
       "      <td>0.694728</td>\n",
       "      <td>0.311092</td>\n",
       "      <td>1.669877</td>\n",
       "      <td>1.160774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045588</td>\n",
       "      <td>0.781521</td>\n",
       "      <td>0.898151</td>\n",
       "      <td>0.232340</td>\n",
       "      <td>0.660326</td>\n",
       "      <td>0.627356</td>\n",
       "      <td>0.317466</td>\n",
       "      <td>0.116915</td>\n",
       "      <td>0.460110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>0.078024</td>\n",
       "      <td>0.146581</td>\n",
       "      <td>0.063674</td>\n",
       "      <td>0.879625</td>\n",
       "      <td>0.198507</td>\n",
       "      <td>0.515858</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.895579</td>\n",
       "      <td>1.506367</td>\n",
       "      <td>0.461575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016633</td>\n",
       "      <td>0.383521</td>\n",
       "      <td>1.302146</td>\n",
       "      <td>0.322049</td>\n",
       "      <td>0.366671</td>\n",
       "      <td>0.466623</td>\n",
       "      <td>0.363642</td>\n",
       "      <td>0.070426</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>0.243431</td>\n",
       "      <td>0.046093</td>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.602414</td>\n",
       "      <td>0.288555</td>\n",
       "      <td>0.382296</td>\n",
       "      <td>0.483439</td>\n",
       "      <td>0.597737</td>\n",
       "      <td>2.293120</td>\n",
       "      <td>0.717919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065328</td>\n",
       "      <td>0.487271</td>\n",
       "      <td>1.349125</td>\n",
       "      <td>0.270184</td>\n",
       "      <td>0.323089</td>\n",
       "      <td>0.485191</td>\n",
       "      <td>0.402267</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.190663</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1955 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1     0.271028  0.208780  0.152388  1.255196  0.453387  0.204274  0.396641   \n",
       "2     0.431392  0.269095  0.121084  1.369295  0.165390  0.200180  0.755715   \n",
       "3     0.189157  0.248151  0.175657  1.353558  0.167985  0.283405  0.603197   \n",
       "4     0.181322  0.431159  0.183613  1.435808  0.244700  0.258571  0.376346   \n",
       "5     0.557896  0.148965  0.297226  1.440755  0.265388  0.100576  0.482407   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1951  0.409747  0.057417  0.243835  1.170132  0.145170  0.518152  1.096409   \n",
       "1952  0.487585  0.064823  0.133818  0.907975  0.518479  0.533047  0.954128   \n",
       "1953  0.432066  0.216163  0.218408  1.073746  0.319600  0.340214  0.694728   \n",
       "1954  0.078024  0.146581  0.063674  0.879625  0.198507  0.515858  0.855469   \n",
       "1955  0.243431  0.046093  0.047530  0.602414  0.288555  0.382296  0.483439   \n",
       "\n",
       "             7         8         9  ...       503       504       505  \\\n",
       "1     0.662290  2.381847  0.763311  ...  0.031166  0.476478  1.420786   \n",
       "2     1.141574  2.679910  0.191846  ...  0.001182  0.298568  1.560464   \n",
       "3     0.640468  1.740507  0.496436  ...  0.028693  0.393584  2.182479   \n",
       "4     1.099299  1.455429  0.377059  ...  0.042131  0.269249  1.557632   \n",
       "5     1.267099  3.177758  0.391448  ...  0.015477  0.503995  1.973315   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1951  0.612581  2.396959  0.879318  ...  0.014551  0.868811  1.065686   \n",
       "1952  0.767510  1.636675  0.891331  ...  0.010044  0.961497  1.074510   \n",
       "1953  0.311092  1.669877  1.160774  ...  0.045588  0.781521  0.898151   \n",
       "1954  0.895579  1.506367  0.461575  ...  0.016633  0.383521  1.302146   \n",
       "1955  0.597737  2.293120  0.717919  ...  0.065328  0.487271  1.349125   \n",
       "\n",
       "           506       507       508       509       510       511  512  \n",
       "1     0.130925  0.158760  0.308012  1.168912  0.035456  0.235910  0.0  \n",
       "2     0.437376  0.089650  0.352928  1.118457  0.044374  0.135839  0.0  \n",
       "3     0.250761  0.181518  0.213455  0.870525  0.115242  0.084740  0.0  \n",
       "4     0.267773  0.207152  0.158261  1.115834  0.108024  0.225783  0.0  \n",
       "5     0.350742  0.277134  0.234877  1.566571  0.074112  0.155174  0.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "1951  0.072270  0.250466  0.306638  0.781481  0.102368  0.035240  1.0  \n",
       "1952  0.163653  0.259980  0.249659  0.396892  0.080202  0.217580  1.0  \n",
       "1953  0.232340  0.660326  0.627356  0.317466  0.116915  0.460110  1.0  \n",
       "1954  0.322049  0.366671  0.466623  0.363642  0.070426  0.396443  1.0  \n",
       "1955  0.270184  0.323089  0.485191  0.402267  0.056035  0.190663  1.0  \n",
       "\n",
       "[1955 rows x 513 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"logistic_regression_40x_features.csv\", index_col=0)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_x_40 = data.iloc[:, :512]\n",
    "labels_40 = data.iloc[:, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(max_iter=5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_40, X_test_40, y_train_40, y_test_40 = train_test_split(feature_set_x_40, labels_40, stratify = labels_40, test_size=0.3)\n",
    "\n",
    "model_40 = LogisticRegressionCV(max_iter = 5000)\n",
    "model_40.fit(X_train_40, y_train_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grace\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegressionCV was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8025613660618997"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_40.score(feature_set_x, labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b9c715b4b5ab98db69d83670635ac4053eadf5168e2010860fffcc3ed36a8e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ds': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
