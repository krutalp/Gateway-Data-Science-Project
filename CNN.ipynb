{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, time, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "import tensorflow as tf \n",
    "# import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elements to Creating a CNN: Base to Extract Features (Convolution and ReLu) and Attach Head \n",
    "\n",
    "cnn = tf.keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(image_size, image_size, 3)),\n",
    "        hub.KerasLayer(model_handle, trainable=True, name='base'),\n",
    "        layers.Dense(512, activation='relu', name='fc1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4, name='dropout'),\n",
    "        layers.Dense(128, activation='relu', name='fc2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ], name=model_name)\n",
    "\n",
    "#Parameters\n",
    "model_name = \"inception_resnet_v2\"\n",
    "IMG_SIZE = model_image_size.get(model_name, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "sample_size = len(train_images)\n",
    "\n",
    "\n",
    "metrics = ['accuracy', Precision(name='Precision'), Recall(name='Recall')]\n",
    "\n",
    "# compiling the model\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)\n",
    "\n",
    "# fit the model\n",
    "train_history = model_nn.fit(train_dataset, epochs=10, batch_size=BATCH_SIZE, verbose=1, validation_data=val_dataset)\n",
    "\n",
    "#model performance \n",
    "\n",
    "model_performance = model_nn.evaluate(val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
